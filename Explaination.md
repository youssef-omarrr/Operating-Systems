# Detailed Documentation for matMultp.c

This document provides an in-depth explanation of the `matMultp.c` source code, which implements multi-threaded matrix multiplication using the POSIX threads (pthreads) library. The program multiplies two matrices using three different multi-threading methods:

1. **Method 1 (Per Matrix):** A single thread computes the entire multiplication.
2. **Method 2 (Per Row):** One thread is created per row of the output matrix.
3. **Method 3 (Per Element):** One thread is created for each element of the output matrix.

The code reads two input matrices from text files, multiplies them using each method, writes the results to corresponding output files, and prints the number of threads created along with the execution time for each method.

---

## Table of Contents

- [Detailed Documentation for matMultp.c](#detailed-documentation-for-matmultpc)
  - [Table of Contents](#table-of-contents)
  - [File Structure](#file-structure)
  - [Global Variables](#global-variables)
  - [Function Explanations](#function-explanations)
    - [read\_matrix](#read_matrix)
    - [write\_matrix](#write_matrix)
    - [multiply\_matrix (Method 1: Per Matrix)](#multiply_matrix-method-1-per-matrix)
    - [multiply\_row (Method 2: Per Row)](#multiply_row-method-2-per-row)
    - [multiply\_element (Method 3: Per Element)](#multiply_element-method-3-per-element)
    - [main](#main)
    - [1. `int argc`](#1-int-argc)
    - [2. `char *argv[]`](#2-char-argv)
    - [How It's Used in the Code](#how-its-used-in-the-code)
    - [Summary](#summary)
  - [**Argument Parsing:**](#argument-parsing)
    - [`snprintf` Function in C](#snprintf-function-in-c)
    - [Syntax:](#syntax)
    - [Return Value:](#return-value)
    - [Example:](#example)
      - [Without `snprintf` (Unsafe `sprintf`):](#without-snprintf-unsafe-sprintf)
      - [With `snprintf` (Safe):](#with-snprintf-safe)
    - [Application in Your Code:](#application-in-your-code)
    - [Why Use `snprintf`?](#why-use-snprintf)
  - [Threading Details](#threading-details)
    - [Thread Creation](#thread-creation)
    - [Thread Synchronization](#thread-synchronization)
    - [Advantages of Multi-threading in the Code](#advantages-of-multi-threading-in-the-code)
  - [Compilation and Execution](#compilation-and-execution)
    - [Compilation](#compilation)
    - [Execution](#execution)
  - [Memory Management and Error Handling](#memory-management-and-error-handling)
    - [Why Use `int *` Instead of `int **`?](#why-use-int--instead-of-int-)
    - [Example Mapping of a 3×3 Matrix](#example-mapping-of-a-33-matrix)
      - [Stored in Memory (Row-Major Order):](#stored-in-memory-row-major-order)
      - [Indexed in a 1D Array:](#indexed-in-a-1d-array)
    - [Why This is Used in the Code](#why-this-is-used-in-the-code)
  - [Conclusion](#conclusion)

---

## File Structure

- **matMultp.c:** Contains the complete C source code.
- **Makefile:** A makefile to compile the code with the correct pthread flags.
- **Input Files:** E.g., `a.txt` and `b.txt` containing the matrices.
- **Output Files:** E.g., `c_per_matrix.txt`, `c_per_row.txt`, and `c_per_element.txt` generated by the program.

---

## Global Variables

The program declares several global variables to hold matrices and their dimensions:

- **Matrix Pointers:**
  - `int *matA, *matB`: Pointers to input matrices A and B.
  - `int *matC_matrix, *matC_row, *matC_element`: Pointers to result matrices computed using the three methods.

- **Dimensions:**
  - `int A_rows, A_cols, B_rows, B_cols`: Dimensions of matrices A and B.
  - `int C_rows, C_cols`: Dimensions of the resulting matrix C (with `C_rows = A_rows` and `C_cols = B_cols`).

---

## Function Explanations

### read_matrix

```c
int *read_matrix(const char *filename, int *rows, int *cols)
```

- **Purpose:**  
  Reads a matrix from a text file.

- **Details:**
  - Opens the file specified by `filename`.
  - Reads the first line which must be in the format:  
    `row=<number> col=<number>`
  - Allocates memory for a one-dimensional array to store the matrix in row-major order.
  - Reads all matrix elements from the file.
  - Returns a pointer to the dynamically allocated matrix or `NULL` if an error occurs.

- **Error Handling:**  
  Checks for file opening errors, valid dimension formatting, and successful memory allocation.

---

### write_matrix

```c
void write_matrix(const char *filename, int *matrix, int rows, int cols)
```

- **Purpose:**  
  Writes a matrix to a text file in the required format.

- **Details:**
  - Opens the file specified by `filename` for writing.
  - Writes the matrix dimensions as the first line:  
    `row=<number> col=<number>`
  - Writes the matrix elements row by row, with elements separated by spaces.

- **Error Handling:**  
  Verifies that the file can be opened for writing and prints an error if not.

---

### multiply_matrix (Method 1: Per Matrix)

```c
void *multiply_matrix(void *arg)
```

- **Purpose:**  
  Computes the full matrix multiplication using a single thread.

- **Details:**
  - Uses the global matrices `matA` and `matB` and stores the result in `matC_matrix`.
  - Iterates over every row `i` and every column `j` of the result matrix.
  - For each element, computes the dot product of the `i`th row of matrix A and the `j`th column of matrix B.
  - Stores the computed sum into `matC_matrix[i * C_cols + j]`.

- **Thread Termination:**  
  Calls `pthread_exit(NULL)` when the computation is complete.

- **Threading Aspect:**  
  Only one thread is created; hence, there is no concurrent execution of parts of the matrix multiplication. This method is primarily used as a baseline for comparison.

---

### multiply_row (Method 2: Per Row)

```c
void *multiply_row(void *arg)
```

- **Purpose:**  
  Computes one row of the result matrix using a separate thread.

- **Details:**
  - Receives a pointer to an integer that represents the row index (allocated on the heap).
  - Frees the allocated memory for the row index after reading it.
  - For the given row, computes each element by performing the dot product between the corresponding row of matrix A and every column of matrix B.
  - Stores the results in the global result matrix `matC_row`.

- **Thread Termination:**  
  Uses `pthread_exit(NULL)` to terminate the thread.

- **Threading Aspect:**  
  A separate thread is created for each row. This allows multiple rows to be computed in parallel, increasing performance when the matrix has many rows.

---

### multiply_element (Method 3: Per Element)

```c
void *multiply_element(void *arg)
```

- **Purpose:**  
  Computes a single element of the output matrix using a dedicated thread.

- **Details:**
  - Accepts a pointer to an `ElemParam` structure (dynamically allocated) that contains the row and column indices.
  - Extracts the row and column values and then frees the allocated structure.
  - Calculates the dot product for the element located at `(row, col)` and stores the result in `matC_element`.

- **Thread Termination:**  
  Calls `pthread_exit(NULL)` upon completion.

- **Threading Aspect:**  
  This method creates one thread per element of the output matrix. While this offers maximum parallelism, it may incur significant overhead for small matrices due to the large number of threads created.

---

### main

```c
int main(int argc, char *argv[])
```

- **Purpose:**  
  Controls the overall flow of the program, handling input, computation, and output.

- **Details:**
is the declaration of the `main` function in C, which serves as the entry point of the program. Let's break it down:

### 1. `int argc`
- `argc` stands for **"argument count."**  
- It represents the number of command-line arguments passed to the program, including the program's name itself.  
- Example:
  ```sh
  ./matMultp a b c
  ```
  Here, `argc = 4` because:
  - `argv[0]` → `"./matMultp"` (program name)
  - `argv[1]` → `"a"`
  - `argv[2]` → `"b"`
  - `argv[3]` → `"c"`

### 2. `char *argv[]`
- `argv` (argument vector) is an **array of strings** (character pointers `char *`).
- Each element in `argv` holds a command-line argument as a C-style string (`char *`).
- Example for `./matMultp a b c`:
  ```c
  argv[0] = "./matMultp"
  argv[1] = "a"
  argv[2] = "b"
  argv[3] = "c"
  ```

### How It's Used in the Code
The program reads the filenames for matrices from command-line arguments:
```c
if (argc < 4) {
    strcpy(inputFileA, "a.txt");
    strcpy(inputFileB, "b.txt");
    strcpy(outputPrefix, "c");
} else {
    snprintf(inputFileA, sizeof(inputFileA), "%s.txt", argv[1]);
    snprintf(inputFileB, sizeof(inputFileB), "%s.txt", argv[2]);
    strcpy(outputPrefix, argv[3]);
}
```
- If fewer than 4 arguments are provided, it defaults to using `"a.txt"`, `"b.txt"`, and `"c"`.
- If 4 or more arguments are given, it uses the provided filenames.

### Summary
- `argc` counts how many arguments were passed.
- `argv` stores the arguments as strings.
- This allows users to specify input/output files when running the program from the terminal.
---
## **Argument Parsing:**  
  Parses command-line arguments to determine the input filenames for matrices A and B, as well as the output file prefix. Defaults to `"a.txt"`, `"b.txt"`, and `"c"` if not provided.

### `snprintf` Function in C

The function `snprintf` is a **safe** version of `sprintf`, used to format a string and store it in a character array while preventing buffer overflows.

### Syntax:
```c
int snprintf(char *str, size_t size, const char *format, ...);
```
- `str`: Pointer to the destination character array where the formatted string is stored.
- `size`: Maximum number of characters to write (including the null terminator `\0`).
- `format`: Format string (similar to `printf`).
- `...`: Additional arguments to format.

### Return Value:
- Returns the number of characters **that would have been written** if the buffer was large enough (excluding the null terminator).
- If the output is **truncated**, the return value is greater than or equal to `size`.

### Example:

#### Without `snprintf` (Unsafe `sprintf`):
```c
char buffer[10];
sprintf(buffer, "HelloWorld");  // No size limit, might cause overflow!
```
❌ This is **unsafe** because `"HelloWorld"` has 10 characters **plus** a null terminator (`\0`), which exceeds the buffer size.

#### With `snprintf` (Safe):
```c
char buffer[10];
snprintf(buffer, sizeof(buffer), "HelloWorld");
```
✅ This ensures that at most **9** characters are written (`sizeof(buffer) - 1` for safety) plus the null terminator.

### Application in Your Code:
```c
snprintf(inputFileA, sizeof(inputFileA), "%s.txt", argv[1]);
```
- Formats `argv[1]` as `<input_name>.txt`.
- Ensures it does **not** exceed `sizeof(inputFileA)`, avoiding buffer overflow.

### Why Use `snprintf`?
1. **Prevents buffer overflows** (unlike `sprintf`).
2. **Ensures safe string formatting**.
3. **Truncates gracefully** if the output is too long.

---
    
  - **Reading Input:**  
    Calls `read_matrix` to load matrices A and B from their respective files.
    
  - **Dimension Validation:**  
    Verifies that the number of columns in matrix A matches the number of rows in matrix B. If not, the program exits with an error.
    
  - **Memory Allocation:**  
    Allocates memory for three different result matrices corresponding to the three multiplication methods.
    
  - **Method 1 Execution (Per Matrix):**  
    - Starts a timer.
    - Creates a single thread to execute the `multiply_matrix` function.
    - Waits for the thread to finish with `pthread_join`.
    - Stops the timer and prints the execution time and the number of threads used.
    
  - **Method 2 Execution (Per Row):**  
    - Allocates an array of thread IDs (one per row).
    - For each row, allocates memory for the row index, creates a thread that runs `multiply_row`, and then joins all threads.
    - Measures and prints the execution time.
    
  - **Method 3 Execution (Per Element):**  
    - Allocates an array of thread IDs (one per element).
    - For each element, allocates an `ElemParam` structure, creates a thread that runs `multiply_element`, and then joins all threads.
    - Measures and prints the execution time.
    
  - **Output:**  
    Constructs output filenames based on the provided prefix and calls `write_matrix` to write each of the three result matrices to file.
    
  - **Cleanup:**  
    Frees all dynamically allocated memory before exiting.

- **Error Handling:**  
  The program checks for errors at each critical step (file operations, memory allocation, thread creation) and exits gracefully if an error occurs.

---

## Threading Details

### Thread Creation

- **pthread_create:**  
  This function is used to start a new thread. For example, in Method 1:
  ```c
  pthread_create(&thread_matrix, NULL, multiply_matrix, NULL);
  ```
  Here, a new thread is created to run the `multiply_matrix` function. The last parameter is used to pass any argument to the thread (if needed).

- **Dynamic Allocation for Thread Parameters:**  
  For Methods 2 and 3, the parameters (row indices or an `ElemParam` structure) are allocated on the heap before being passed to the thread function. This ensures that each thread receives its own copy of the required data. These allocations are freed within the thread functions once they are no longer needed.

### Thread Synchronization

- **pthread_join:**  
  After launching threads, the main thread calls `pthread_join` for each one. This call blocks the main thread until the specified thread has completed. It ensures that the program waits for all threads to finish their computation before proceeding to the next step (like writing output files).

- **Avoiding Sequential Execution:**  
  The code deliberately creates all worker threads first and only then joins them. This maximizes parallel execution rather than waiting for each thread to finish immediately after it is created.

### Advantages of Multi-threading in the Code

- **Parallel Computation:**  
  By dividing the work among multiple threads, the matrix multiplication can run concurrently on multi-core processors. This is particularly beneficial for large matrices or when the computational load is high.

- **Different Granularities:**  
  - **Per Matrix:** Minimal thread overhead but limited parallelism.
  - **Per Row:** A balanced approach that reduces overhead while still utilizing multiple cores.
  - **Per Element:** Maximizes parallelism; however, for small matrices the thread creation overhead may be high compared to the computation time.

- **No Synchronization Primitives Needed:**  
  Since each thread writes to a unique part of the result matrix (a specific row or element), there is no contention for shared resources. This means that there is no need for mutexes or semaphores, simplifying the design and avoiding common pitfalls in concurrent programming.

---

## Compilation and Execution

### Compilation

Ensure you compile the code with the pthread flag to link the pthread library:

```bash
gcc -pthread -Wall -o matMultp matMultp.c
```

Alternatively, use the provided Makefile which includes the necessary flags.

### Execution

Run the executable with the following command:

```bash
./matMultp a b c
```

- **Input Files:**  
  The program will read from `a.txt` and `b.txt`.

- **Output Files:**  
  The results will be written to `c_per_matrix.txt`, `c_per_row.txt`, and `c_per_element.txt`.

---

## Memory Management and Error Handling

- **Dynamic Memory Allocation:**  
  The program uses `malloc` for allocating space for matrices and thread parameters. Every allocation is checked to ensure it was successful.

- **Freeing Allocated Memory:**  
  Memory allocated for thread parameters in Methods 2 and 3 is freed within the thread functions after use. Global matrices and output arrays are freed at the end of the main function.

- **Error Checks:**  
  Each critical operation (file I/O, memory allocation, thread creation) is followed by error handling. If any error occurs, a relevant error message is printed and the program exits gracefully.

---

The matrices (`matA`, `matB`, `matC_matrix`, etc.) are declared as `int *` (instead of `int **`) because they are stored in a **contiguous 1D array** in memory rather than a 2D array of pointers.  

### Why Use `int *` Instead of `int **`?  
In C, a 2D array is essentially an array of arrays, and it can be stored in two ways:  
1. **As an array of pointers (`int **`)**:  
   - This requires allocating an array of row pointers, each pointing to a dynamically allocated array for columns.  
   - Example:  
     ```c
     int **matrix = malloc(rows * sizeof(int *));
     for (int i = 0; i < rows; i++)
         matrix[i] = malloc(cols * sizeof(int));
     ```
   - **Downside**: More complex memory allocation and access (requires double dereferencing `matrix[i][j]`).

2. **As a single contiguous 1D array (`int *`)** (used in the code):  
   - Instead of a pointer to an array of pointers, the entire matrix is stored in a single block of memory.
   - Example:
     ```c
     int *matrix = malloc(rows * cols * sizeof(int));
     ```
   - To access an element at row `i` and column `j`, use:  
     ```c
     matrix[i * cols + j]
     ```
   - **Advantages**:  
     - Memory is allocated in a single contiguous block (better cache performance).  
     - Avoids the extra memory required for storing row pointers.  
     - Easier to pass to functions and compatible with parallelization techniques.

### Example Mapping of a 3×3 Matrix
#### Stored in Memory (Row-Major Order):
```
Matrix:
  1  2  3
  4  5  6
  7  8  9
```
#### Indexed in a 1D Array:
```
Index:    0  1  2  3  4  5  6  7  8
Value:    1  2  3  4  5  6  7  8  9
```
To access `matrix[1][2]` (row `1`, column `2`):
```c
matrix[1 * 3 + 2]  // = matrix[5] = 6
```

### Why This is Used in the Code
- The multiplication function accesses elements using `matA[i * A_cols + k]` instead of `matA[i][k]`.  
- It simplifies memory management since only **one call to `malloc`** is needed per matrix.  
- It works well with threading and avoids additional pointer indirections.

---

## Conclusion

The `matMultp.c` program is a comprehensive example of using pthreads for multi-threaded matrix multiplication. By exploring three methods—per matrix, per row, and per element—it highlights the trade-offs between thread management overhead and potential parallelism. The detailed commentary in this document explains every function and the rationale behind the threading approach used. This understanding is vital for optimizing parallel computations and for further extending the application in high-performance computing scenarios.

---